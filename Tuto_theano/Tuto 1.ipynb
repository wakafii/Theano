{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de base de theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer voyons les quelques fonctions \"basiques\" de theano dont nous auront besoin pour la suite de ces tutoriels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déclarer des variables et executer des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord nous avons besoin d'importer différentes librairie python ainsi que theano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano import *\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant voir les différents types de variables que nous pouvons utiliser avec theano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les variables dites \"statiques\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer par les variables \"classiques\", elles peuvent prendre plusieurs type donnés ci après:\n",
    "* byte: bscalar, bvector, bmatrix, brow, bcol, btensor3, btensor4, btensor5, btensor6, btensor7\n",
    "* 16-bit integers: wscalar, wvector, wmatrix, wrow, wcol, wtensor3, wtensor4, wtensor5, wtensor6, wtensor7\n",
    "* 32-bit integers: iscalar, ivector, imatrix, irow, icol, itensor3, itensor4, itensor5, itensor6, itensor7\n",
    "* 64-bit integers: lscalar, lvector, lmatrix, lrow, lcol, ltensor3, ltensor4, ltensor5, ltensor6, ltensor7\n",
    "* float: fscalar, fvector, fmatrix, frow, fcol, ftensor3, ftensor4, ftensor5, ftensor6, ftensor7\n",
    "* double: dscalar, dvector, dmatrix, drow, dcol, dtensor3, dtensor4, dtensor5, dtensor6, dtensor7\n",
    "* complex: cscalar, cvector, cmatrix, crow, ccol, ctensor3, ctensor4, ctensor5, ctensor6, ctensor7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour déclarer une variable il suffit de lui indiquer son nom, son type et une string pour la décrire. Toutes les types de variables sont contenus dans theano.tensor. Voyons un example où nous déclarons x un dscalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.dscalar('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons essayer avec plusieurs type de variables, essayez de déclarer une matrice a de double et un vecteur b de float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlevez les dies avant de compiler\n",
    "# a = ...\n",
    "# b = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les variables partagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi déclarer des variables partagées dont la valeur pourra être modifiée et sauvegarder lors des appels de fonctions ( que nous verrons plus loin ). Pour cela il suffit d'indiquer la valeur de départ de la variable et son nom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = theano.shared(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction shared de theano peut prendre tous les types de variables, example avec un tableau de valeurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = theano.shared(  value=numpy.zeros((0,10),dtype=theano.config.floatX),  name='x',  borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(x.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les fonctions avec theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'executer des opérations sous theano il faut déclarer des fonction que l'on appelera, pour cela il faut au préalable définir les operations à effectuer ainsi que déclarer les variables de ces opérations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on définit la fonction, pour cela nous devons indiquer les variables qui doivent être passées en arguments lors de l'appel ainsi que l'opération concernée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = function([x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant executer notre fonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi effectuer des operations entre des variables de taille differentes, exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  4.],\n",
       "       [ 4.,  5.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dscalar('x')\n",
    "y = T.dmatrix('y')\n",
    "z = x + y\n",
    "f = function([x, y], z)\n",
    "f(2, [[3,2],[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi possible d'executer plusieur opérations en même temps grâce à un appel de fonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.],\n",
       "        [-1., -2.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  2.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  4.]]), array([[ 6.,  5.],\n",
       "        [ 6.,  9.]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = T.dmatrices('a', 'b')\n",
    "y = T.dscalar('y')\n",
    "diff = a - b\n",
    "abs_diff = abs(diff)\n",
    "diff_squared = diff**2\n",
    "z = y + diff_squared\n",
    "f = theano.function([a, b, y], [diff, abs_diff, diff_squared, z])\n",
    "f([[1, 1], [1, 1]], [[0, 1], [2, 3]], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les fonctions pour les variables partagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu plus haut les variables partagées sauvegardent leurs données à chaque appel de fonction, on peut voir ces variables comme des compteurs sur lequel nous allons appliquer des opérations, l'exemple ci dessous montre une fonction comprenant une variable partagée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = shared(0)\n",
    "inc = T.iscalar('inc')\n",
    "accumulator = function([inc], state, updates=[(state, state+inc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer la valeur de notre variable à n'importe quel moment grâce à la fonction state.get_value() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulator(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialiser un argument dans une fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut, lors de la déclaration d'une fonction, initialiser un de ses arguments avec une valeur par défaut, cela nous permettra de pouvoir appeler cette fonction avec ou sans cet argument. Les arguments initialisés par une valeur par défaut doivent se trouver en fin de déclaration de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = T.dscalars('x', 'y')\n",
    "z = x + y\n",
    "f = function([x, In(y, value=1)], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(34.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(35.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(33,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les fonctions random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se servir des fonctions random de la librairie theano il faut les importer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant utiliser les différentes fonctions random de la librairie, pour commencer nous devons instancier un seed pour générer les nombres aléatoirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "srng = RandomStreams(seed=234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous pouvons créer les oprerations qui générerons les nombres aléatoires, pour cela plusieurs methodes nous sont proposées par la librairie theano, ici nous utilisons les methodes uniform et normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_u = srng.uniform((2,2)) #nous indiquons dans la fonction les dimensions que prend notre variable aléatoire, ici une matrice 2,2\n",
    "rv_n = srng.normal((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin il nous suffit de déclarer des fonctions executant ces operations et de les appeler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31971415,  0.47584377],\n",
       "       [ 0.24129163,  0.42046081]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = function([], rv_u)\n",
    "g = function([], rv_n, no_default_updates=True)\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37328447, -0.65746672],\n",
       "       [-0.36302373, -0.97484625]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons vu comment déclarer des variables ainsi que les différentes notions sur les fonctions avec theano nous allons essayer de programmer un modèle basique de réseau de neurone avec theano, pour cet exemple nous nous baserons sur le modèle de la \"Logistic Regression\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer importons les librairies qu'il nous manque pour cet exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code du programme, certaine partie sont a completer par vous même:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = numpy.random\n",
    "\n",
    "N = 400                                   # training sample size\n",
    "feats = 784                               # number of input variables\n",
    "\n",
    "# generate a dataset: D = (input_values, target_class)\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
    "training_steps = 10000\n",
    "\n",
    "# Declare Theano symbolic variables\n",
    "x = #declarez x une matrice de double\n",
    "y = #declarez y un vecteur de double\n",
    "\n",
    "# initialize the weight vector w randomly\n",
    "#\n",
    "# this and the following bias variable b\n",
    "# are shared so they keep their values\n",
    "# between training iterations (updates)\n",
    "w = #déclarez w les poids du graphe en tant que variable partagée initialisée de façon aléatoire en fonction de feats (rng.randn(feats))\n",
    "\n",
    "# initialize the bias term\n",
    "b = #déclarez w les biais du graphe en tant que variable partagée initialisée à 0\n",
    "\n",
    "print(\"Initial model:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "\n",
    "# Construct Theano expression graph\n",
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1\n",
    "prediction = p_1 > 0.5                    # The prediction thresholded\n",
    "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n",
    "cost = xent.mean() + 0.01 * (w ** 2).sum()# The cost to minimize\n",
    "gw, gb = T.grad(cost, [w, b])             # Compute the gradient of the cost\n",
    "                                          # w.r.t weight vector w and\n",
    "                                          # bias term b\n",
    "                                          # (we shall return to this in a\n",
    "                                          # following section of this tutorial)\n",
    "\n",
    "# Compile\n",
    "train = #déclarez une fonction avec les paramètres suivants:\n",
    "                              #entrées : x,y\n",
    "                              #sorties : prediction, xent\n",
    "                              #updates : (w, w - 0.1 * gw), (b, b - 0.1 * gb)\n",
    "predict = #déclarez une fonction avec les paramètres suivants:\n",
    "                              #entrée : x\n",
    "                              #sortie : prediction\n",
    "\n",
    "# Train\n",
    "for i in range(training_steps):\n",
    "    pred, err = train(D[0], D[1])\n",
    "\n",
    "print(\"Final model:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "print(\"target values for D:\")\n",
    "print(D[1])\n",
    "print(\"prediction on D:\")\n",
    "print(predict(D[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
